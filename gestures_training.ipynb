{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-11T17:45:21.069165Z",
     "start_time": "2025-11-11T17:45:21.067127Z"
    }
   },
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "\n",
    "#from load_keypoints import bodypart_index"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T17:45:22.465389Z",
     "start_time": "2025-11-11T17:45:22.443639Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = []\n",
    "with open(\"pose_data.json\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        data.append(json.loads(line))"
   ],
   "id": "69d34830c738dce6",
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Extra data: line 1 column 17659 (char 17658)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mJSONDecodeError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[14], line 4\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpose_data.json\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[1;32m      3\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i, line \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(f):\n\u001B[0;32m----> 4\u001B[0m         data\u001B[38;5;241m.\u001B[39mappend(\u001B[43mjson\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloads\u001B[49m\u001B[43m(\u001B[49m\u001B[43mline\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/json/__init__.py:346\u001B[0m, in \u001B[0;36mloads\u001B[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001B[0m\n\u001B[1;32m    341\u001B[0m     s \u001B[38;5;241m=\u001B[39m s\u001B[38;5;241m.\u001B[39mdecode(detect_encoding(s), \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msurrogatepass\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    343\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\u001B[38;5;28mcls\u001B[39m \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m object_hook \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m\n\u001B[1;32m    344\u001B[0m         parse_int \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m parse_float \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m\n\u001B[1;32m    345\u001B[0m         parse_constant \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m object_pairs_hook \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m kw):\n\u001B[0;32m--> 346\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_default_decoder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43ms\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    347\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mcls\u001B[39m \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    348\u001B[0m     \u001B[38;5;28mcls\u001B[39m \u001B[38;5;241m=\u001B[39m JSONDecoder\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/json/decoder.py:340\u001B[0m, in \u001B[0;36mJSONDecoder.decode\u001B[0;34m(self, s, _w)\u001B[0m\n\u001B[1;32m    338\u001B[0m end \u001B[38;5;241m=\u001B[39m _w(s, end)\u001B[38;5;241m.\u001B[39mend()\n\u001B[1;32m    339\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m end \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mlen\u001B[39m(s):\n\u001B[0;32m--> 340\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m JSONDecodeError(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExtra data\u001B[39m\u001B[38;5;124m\"\u001B[39m, s, end)\n\u001B[1;32m    341\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m obj\n",
      "\u001B[0;31mJSONDecodeError\u001B[0m: Extra data: line 1 column 17659 (char 17658)"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "vid_index = 0\n",
    "frame_index = 0\n",
    "bodypart_index = 0\n",
    "data[vid_index]['keypoints'][frame_index][bodypart_index][:2]"
   ],
   "id": "c517fb0a950b941",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_positions(data, video_index):\n",
    "    video_entry = data[video_index]\n",
    "    gesture_id = video_entry['gesture_id']\n",
    "    keypoints = np.array(video_entry['keypoints'])\n",
    "    keypoints = keypoints[:, :, :2]\n",
    "    return keypoints"
   ],
   "id": "8ef80fc007515d89",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_velocitys(data, video_index):\n",
    "    video_entry = data[video_index]\n",
    "    gesture_id = video_entry['gesture_id']\n",
    "    keypoints = np.array(video_entry['keypoints'])\n",
    "    keypoints = keypoints[:, :, :2]\n",
    "\n",
    "    velocities = np.diff(keypoints, axis=0)\n",
    "    return velocities"
   ],
   "id": "5ef440fc032ec54d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_position_velocity(data, video_index):\n",
    "    positions = get_positions(data, video_index)\n",
    "    velocities = get_velocitys(data, video_index)\n",
    "\n",
    "    merged = np.concatenate([positions[:-1], velocities], axis=-1)\n",
    "    return merged"
   ],
   "id": "636e0fa2f2d2698a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for i in range(0, len(data)):\n",
    "    keypoints = data[i]['keypoints']\n",
    "    gesture_id = data[i]['gesture_id']\n",
    "\n",
    "    if keypoints:\n",
    "        X = get_position_velocity(data, i)\n",
    "        Y = gesture_id"
   ],
   "id": "55a5f1d1f88e6d2d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import random\n",
    "# -------------------------\n",
    "# Dataset definition\n",
    "# -------------------------\n",
    "class PoseGestureDataset(Dataset):\n",
    "    def __init__(self, data, get_position_velocity_fn):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data: list of dicts, each like {'keypoints': ..., 'gesture_id': ...}\n",
    "            get_position_velocity_fn: function(data, i) -> torch.Tensor or np.ndarray\n",
    "        \"\"\"\n",
    "        self.samples = []\n",
    "        for i in range(len(data)):\n",
    "            keypoints = data[i].get('keypoints')\n",
    "            gesture_id = data[i].get('gesture_id')\n",
    "\n",
    "            if keypoints:\n",
    "                X = get_position_velocity_fn(data, i)  # (Ni, 17, 4)\n",
    "                Y = gesture_id\n",
    "                if isinstance(X, np.ndarray):\n",
    "                    X = torch.tensor(X, dtype=torch.float32)\n",
    "                self.samples.append((X, Y))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X, Y = self.samples[idx]\n",
    "        X = X.view(X.shape[0], -1)  # flatten to (Ni, 68)\n",
    "        return X, torch.tensor(Y, dtype=torch.long)\n",
    "\n",
    "    # shuffle the samples\n",
    "    def shuffle(self, seed = 42):\n",
    "        random.seed(seed)\n",
    "        self.samples = random.sample(self.samples, len(self.samples))\n"
   ],
   "id": "a35617b16cdbf69",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# -------------------------\n",
    "# Collate function for variable-length sequences\n",
    "# -------------------------\n",
    "def pad_collate_fn(batch):\n",
    "    sequences = [item[0] for item in batch]\n",
    "    labels = torch.tensor([item[1] for item in batch], dtype=torch.long)\n",
    "    lengths = [seq.shape[0] for seq in sequences]\n",
    "\n",
    "    padded_X = torch.nn.utils.rnn.pad_sequence(sequences, batch_first=True)\n",
    "    return padded_X, labels, torch.tensor(lengths, dtype=torch.long)\n",
    "\n",
    "\n",
    "def get_position_velocity(data, i):\n",
    "    N = np.random.randint(50, 150)  # random number of frames\n",
    "    return np.random.rand(N, 17, 4)\n",
    "\n",
    "# -------------------------\n",
    "# Example usage\n",
    "# -------------------------\n",
    "# Create dataset and dataloader\n",
    "dataset = PoseGestureDataset(data, get_position_velocity)\n",
    "dataset.shuffle(seed = 10)\n",
    "\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "    collate_fn=pad_collate_fn\n",
    ")\n",
    "\n",
    "# Inspect one batch\n",
    "for X, Y, lengths in loader:\n",
    "    print(\"Batch X shape:\", X.shape)   # (batch_size, max_seq_len, 68)\n",
    "    print(\"Batch Y shape:\", Y.shape)   # (batch_size,)\n",
    "    print(\"Sequence lengths:\", lengths)\n",
    "\n",
    "    print(X)\n",
    "    print(Y)\n",
    "    break"
   ],
   "id": "25bddefebc37d08c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# ----- Dataset -----\n",
    "dataset = PoseGestureDataset(data, get_position_velocity)\n",
    "\n",
    "# ----- Split -----\n",
    "total_len = len(dataset)\n",
    "train_ratio, val_ratio, test_ratio = 0.7, 0.15, 0.15\n",
    "train_len = int(total_len * train_ratio)\n",
    "val_len = int(total_len * val_ratio)\n",
    "test_len = total_len - train_len - val_len\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_len, val_len, test_len])\n",
    "\n",
    "# ----- DataLoaders with padding collate_fn -----\n",
    "batch_size = 8\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True, collate_fn=pad_collate_fn\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=batch_size, shuffle=False, collate_fn=pad_collate_fn\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=batch_size, shuffle=False, collate_fn=pad_collate_fn\n",
    ")\n",
    "\n",
    "# ----- Verify -----\n",
    "for X, Y, lengths in train_loader:\n",
    "    print(\"Train batch X shape:\", X.shape)\n",
    "    print(\"Train batch Y shape:\", Y.shape)\n",
    "    print(\"Sequence lengths:\", lengths)\n",
    "    break"
   ],
   "id": "e34ca8cacf51e44",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# -------------------------\n",
    "# Assume dataset and pad_collate_fn are already defined\n",
    "# and train_loader, val_loader, test_loader exist\n",
    "# -------------------------\n",
    "\n",
    "# ----- Bi-LSTM Model -----\n",
    "class BiLSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_size=68, hidden_size=128, num_layers=2, num_classes=3):\n",
    "        super(BiLSTMClassifier, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_size * 2, num_classes)  # *2 for bidirectional\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        # Pack padded sequences\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        packed_out, (hn, cn) = self.lstm(packed)\n",
    "        # Concatenate last hidden states from both directions\n",
    "        out = torch.cat((hn[-2], hn[-1]), dim=1)  # shape: (batch, hidden*2)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# ----- Training Setup -----\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_classes = len(set([data[i]['gesture_id'] for i in range(len(data)) if data[i]['keypoints']]))\n",
    "model = BiLSTMClassifier(num_classes=num_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# ----- Training Loop -----\n",
    "num_epochs = 50  # adjust as needed\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    total_loss = 0\n",
    "\n",
    "    for X, Y, lengths in train_loader:\n",
    "        X, Y, lengths = X.to(device), Y.to(device), lengths.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X, lengths)\n",
    "\n",
    "        loss = criterion(outputs, Y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * Y.size(0)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        total_correct += (preds == Y).sum().item()\n",
    "        total_samples += Y.size(0)\n",
    "\n",
    "    train_acc = total_correct / total_samples\n",
    "    train_loss = total_loss / total_samples\n",
    "\n",
    "    # ----- Validation -----\n",
    "    model.eval()\n",
    "    val_correct = 0\n",
    "    val_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for X_val, Y_val, lengths_val in val_loader:\n",
    "            X_val, Y_val, lengths_val = X_val.to(device), Y_val.to(device), lengths_val.to(device)\n",
    "            outputs_val = model(X_val, lengths_val)\n",
    "            preds_val = outputs_val.argmax(dim=1)\n",
    "            val_correct += (preds_val == Y_val).sum().item()\n",
    "            val_samples += Y_val.size(0)\n",
    "\n",
    "    val_acc = val_correct / val_samples\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | \"\n",
    "          f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc*100:.2f}% | \"\n",
    "          f\"Val Acc: {val_acc*100:.2f}%\")"
   ],
   "id": "ad0ef52c71b03785",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ----- Test Accuracy -----\n",
    "model.eval()\n",
    "test_correct = 0\n",
    "test_samples = 0\n",
    "with torch.no_grad():\n",
    "    for X_test, Y_test, lengths_test in test_loader:\n",
    "        X_test, Y_test, lengths_test = X_test.to(device), Y_test.to(device), lengths_test.to(device)\n",
    "        outputs_test = model(X_test, lengths_test)\n",
    "        preds_test = outputs_test.argmax(dim=1)\n",
    "        test_correct += (preds_test == Y_test).sum().item()\n",
    "        test_samples += Y_test.size(0)\n",
    "\n",
    "test_acc = test_correct / test_samples\n",
    "print(f\"Test Accuracy: {test_acc*100:.2f}%\")"
   ],
   "id": "9f8685cd4c2826b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ----- Make predictions on test set -----\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for X_test, Y_test, lengths_test in test_loader:\n",
    "        X_test, Y_test, lengths_test = X_test.to(device), Y_test.to(device), lengths_test.to(device)\n",
    "        outputs = model(X_test, lengths_test)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(Y_test.cpu().numpy())\n",
    "\n",
    "# ----- Compute confusion matrix -----\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# ----- Plot -----\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ],
   "id": "25612353a9286e5d",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
